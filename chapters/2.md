Polymer and web components make a promise that other javascript web frameworks aren't structurally suited to deliver on: the competitive web. And that's because the only way you can make the web better, and faster, is to send less stuff. Devices spend most of their time being not useful with network requests, and parsing javascript. If the browser does more, you can send less.

This makes it the only longer-term choice. But more than that, I think it's entirely possible to ship sellable software in a timely manner with it, right now. In tandem with, or without, other web frameworks. There are areas of Polymer/Web components that suck and get in the way of shipping which frameworks do better. But there are simple/attainable paths we can take to shore up those weaknesses, adopt all the upsides of frameworks without all the drawbacks. I haven't done it - yet - simply because I haven't had enough time. But we were able to stand up this site, get it into production, and have multiple PR's merged in from different developers *who were brand new to Polymer* inside three weeks. I think it's not only entirely possible, but easily replicatable across an organization. This post outlines exactly what I think needs to happen to execute on that, and *why*.

## Why Programs Exist

Strictly speaking, you don't ever write code to write code. I don't mean "*you can't spend nights and weekends coding for pleasure, you must always code for work!*" But code is just like speech. You don't speak just to speak, you speak so you're heard. So someone else receives, understands, is moved. Without that person at the other end, why speak at all in the first place? The act of speaking loses it's value, especially if much more efficient forms of communication with yourself exist. If you don't have other people you need to influence, rhetoric isn't worth anything.

Software is like speaking, in that the only reason it exists is because it helps other people get some sort of job done. Without that job getting accomplished at the other end, all the supporting infrastructure behind code wouldn't be worth it.

In exchange for taking some scarcity in the world, and building a system that makes that previously scarce/valuable resource abundant, people pay money for it. (For example, that kern machine that sends out the oodles of letters takes the previously scarce resource of preparing letters, and makes it abundant.) Code is often taking the expertise of a person and putting that expertise into a computer. Code is just thought. It's a series of selections from how the world really is explained so clearly a computer can understand and behave with either the judgement or skill of a human in a specific area. So the best code, and the best programmer is not so much directly a programmer, but a system that's capable of efficiently and valuably interpreting and communicating the process of the real world in software.

What's scarce in any organization deploying software is usually money. And since all other sorts of costs can be translated into money (which is one of the main purposes of money, after all), it's a really efficient way of talking about software. So the right way of talking about software is in dosages of cost: both how much, and when.

I think, pound for pound, Polymer/Web Components have a somewhat uncapped upside in the amount of value you can get per unit of cost. In plain english, I think I'll be able to ship FAR more awesome software far faster and cheaper than any of the other alternatives. By becoming skilled at building things with web components, I personally will be able to ship faster, better, more maintainably, more performant than someone who doesn't.

That said, given my time using it, I think there's a specific of tools and approaches that either need to be adopted or built in order to realize this completely asymmetrical gain. AKA, if you wanna be able to ship maintainable code that gets the job done really fast, there's some stuff missing.

## Simple vs Easy

Before I dive in, I need to make a distinction.

A thing is **simple** when it adopts the minimum amount of complexity needed to achieve it's purpose. This doesn't mean, it lacks complexity. If you're dealing with a really complicated domain, you will necessarily need some amount of complexity. Simple means a thing lacks *unnecessary* complexity.

**Easy** means familiar. Something's easy if you're familiar with it. People don't like stuff they suck at, and how good you are at something is usually a function of how much time you've spent trying to get good at it.

Ease tends to correspond with simplicity. The simpler something is, the quicker you can pick it up. But easy does not mean simple. Just because something is familiar, doesn't mean that's the best choice. This dynamic is, quite reasonably, strongly at play when comparing a javascript web framework (React, Vue, Angular) with Polymer/Web Components.

As someone who's satisfaction in life is primarily derived from my ability to ship software which actually helps other people get $^@# done, I think Polymer/Web components are the most simple and expressive building blocks available. I was not familiar with them (I come from a React/Angular/Vanilla Jquery background), but now that I am, there's no other choice. Because if they don't work, the web doesn't work. What I see in them is: leverage. Outsized impact. I want to ship software that'll get used by everyone in the world, and I think this is my best shot.

But there are parts of developing with Polymer that suck. There are places where, right now, frameworks do it better. There are some glaring weaknesses in the Polymer/Web components ecosystem. So then, what are the right questions?

* What sucks?
* What are the costs of the fixing these sucky parts?

The whole point of software is to help someone else get a job done. And the only discussion that matters from the business perspective is one of doses of cost. How much, how long, will building that software take?

Any discussion about velocity in a specific context boils down to an investigation of a single moment. As a programmer, when I know what I'm trying to do, and I'm staring at some actual code, trying to do it, what happens when I get stuck?

This 'stuck' moment will happen hundreds, thousands of times across the course of a project. What determines velocity isn't whether stuck moments will be there, but how many there are, and how long it takes each individual to get past each one.

## Getting past Stuck

The first thing that happens when a programmer is staring at a piece of code and they don't know what to do next is fall back on their mental model of what's happening. Mental models can be more or less aligned with the way reality actually is. The more accurate they are, the more complete, the faster and better the next guess of that programmer will be. A mental model produces the story of what's happening. That story is either accurate, and gets you closer to shipping software, or inaccurate, and you waste time.

What builds good mental models? Two things. First, is teaching material. The act of incrementally building upon existing knowledge so you arrive at some place where a person has a pretty good idea about how a thing behave, so when they introduce changes to it it behaves the way they expect. The second thing, is reference material. Once you have a sound mental model, you won't be able to keep everything in your head all at once. As long as the cost of accessing that information is really low, then this is actually a far more effective approach than trying to remember everything.

Both the teaching phase, and the reference phase, are both all wrapped up into one word: documentation. And this is an area where Polymer sucks, and frameworks have a leg up. Because the Polymer team at Google decided on a market entry strategy that focuses their efforts on specific other large companies, all of the documentation is written by technical people in the know for technical people in the know. That is to say, it's all reference material. Add to that, that they're trying to do something brand new, they're gonna make mistakes. They're gonna need to change direction and revise their approach.

This makes it really really hard for new people who aren't already in the know to build good mental models. And this is a place where, because frameworks target developers in general, and are typically quite stable, the teaching documentation is both good and stays relevant over longer periods of time.

### Getting developers developing, fast

So how do we fix this? Simple. Better teaching material. What makes good teaching material? The right content, in the right sequence. So that, from day one, as a developer who wants to be able to ship via Polymer/Web components, you have a map. You know what you need to learn, and there are effective, obvious paths for you to get there.

If you ask any teacher, they will tell you the phrase, "Students will be able to..."

Aka, "students will be able to *what*?" After they've consumed a lesson, they will be able to do what they couldn't do before? Once you know this, the map of what needs to happen and the sequence in which it happens, you need to build each unit. Each lesson needs to emphasize *teaching*, not *being reference material*.

Good:
1. Finds motivation
2. Build incrementally
3. Actually know

Bad:
1. Precise
2. Detailed
3. "Entertaining" (relies on cheap schticks to keep attention)

Other frameworks have this, because they target general developers and newbs. Polymer doesn't, because their market entry strategy is already technical people.

Building this teaching material is not hard. In fact, it's what this site is. This first guide is generalized developer onboarding. There are a discrete amount of things to learn, and a right sequence in which to learn them. Since they're about what is fundamentally *the web,* they are a risk-less investment for any developer who makes stuff on the web.

### State Management

Once a developer has a solid enough mental model, they can start shipping things to production. The next moment full of stuck is a specific one.

When I'm looking at a specific chunk of code on a specific place on the page, how do I know what other data I have access to? How do I know what the scope is? Then, once I have that data, how do I know the right thing to do with it? How complex is the design of that system?

There's a way of measuring this, which has a name that I hate. It's called *cyclomatic complexity*. Despite how big and hairy the word is, it's really simple. A cyclomatic complexity analysis is just a count of all the different possible paths that can happen in a piece of code.

```
if (person === admin) {
  doThisThing();
} else {
  doThisOtherThing();
}
```

If you were to cyclomatically analyze the complexity of that piece of code, it would be two, because two things can happen. You'll either do this thing, or do that other thing, depending on if the person is an admin or not. So when you're looking at a specific piece of code, trying to debug it, what you're really doing is navigating a system with a certain amount of complexity. The more things you have to consider, the longer it takes, the less, the quicker you can change stuff.

And the lion's share of complexity is state. Any information on a web page that changes is *state*. On complex web pages, with lots of things going on, there's tons of state. The fundamental problem that every framework addresses is how to manage this state. If everybody agrees on "here's how we're going to deal with this common situation," then you can effectively move from one code base to another because you can rely on the same mental model for both places. One of the biggest responsibilities of frameworks are to be formalized conventions around the flow of state.

Other javascript web frameworks have a leg up on Polymer/Web components in terms of state management, intiially. But...if we have a way to manage state that's not a javascript web framework, we get all of the benefits of Polymer/Web components with none of the downsides.

Polymer/Web components deal with state like this.

![01 mediator pattern](/images/chapters/2/01.png)

There's a "mediator," who's job is to hold a bunch of data, and a bunch of other components. That mediator controls how that data flows. So, on an isolated individual level, this is pattern is super clear about where data lives. For example, this is every form on a webpage everywhere ever.

But this pattern exists in a higher context: a web page. And the way a web page is set up, is like a big tree (or graph). So you'll have a bunch of things on a web page, inside a bunch of other things.

![02 plain view of a dom tree](/images/chapters/2/02.png)

So, say I'm trying to debug some form that's not saving correctly. Is it not sending data to the server the right way? Or is it not getting data from the server back the right way? What's happening? That form is somewhere in the big "DOM Tree," which is to say, the representation of everything that's on the page in a way a computer can understand it.

![03 pointing out form](/images/chapters/2/03.png)

So the first thing a programmer has to do is figure out where it's getting it's data from.

![04 data flow](/images/chapters/2/04.png)

This blue line has a complexity of 2, because it takes two trips across two different places. This is an example of a *property*, or just a piece of information that one component passes down to another component.

But data can flow other ways than just a property that gets passed down. Data can flow through events. An event says "something happened! and here's what happened!" And, this is where we begin to get a little crazy, every time anything on a page sends an event, all of it's ancestors see it.

![events](/images/chapters/2/05.png)

So now, to track down this bug, we don't just need to consider the property. We need to consider all the events that might be the source of the problem, too. So now our cyclomatic complexity is up to 8 - six for the events, two for the properties.

But there's more. There's this thing called two way data binding. This is used heavily in Angular 1.x, and can (but doesn't have to be) used in Polymer/Web components. This means, if you change a property in one place, every other place that uses that property changes, too.

![two way data binding](/images/chapters/2/06.png)

And remember, events can affect properties.

![two way data binding + events](/images/chapters/2/07.png)

Cyclomatic complexity: crazy. 22.

And so that means, in order to understand what's introducing this bug in this one place in the code and add a fix that doesn't break other stuff, the thing adding the bug might be somewhere way far away from where you're looking. And there's no good way to know - the only way is to manually trace through each path.

And it gets worse - an event that mutates a needed property way over there might itself have an entire dependency chain of *other* code that you have to understand. And so, honestly, the graph I've drawn here would be a relatively simple webpage - a header with some navigation links, a form, and a view of something else.

What's important is not the specific cyclomatic complexity number. What's important is, as you need to build more complex applications with more developers and more functionality on each page, how much does the complexity a programmer will have to deal with grow? What is it's rate of growth?

*It explodes.* There's not a mathematically sound measure of this, since it really depends on your specific configuration, but I'd just say, the complexity of the amount of pieces a programmer has to understand to add a fix goes up at like n^3 for a poorly constructed page.

And most of the time, choosing the right path is guesswork. This is why debugging takes so long. And when you don't have tests, you don't get automated feedback from the system on what's broken where, or why. So then you have to manually go through and reverify every other piece of functionality to add one fix to one piece.

This is crazy. Frameworks address this by defining how state flows. This is where the velocity gains come from. Because people are able to accurately reason about and predict the behavior of the system they were working in.

So what if, instead of adopting a whole framework, we just adopted the piece we needed? The state management?

That state management approach is called the *flux* pattern, popularized by Facebook, and it's one principal reasons React is so popular. It's why Angular 2/4 had to come out, and why the transition from Angular 1.x to 2 is so hard (under the hood, it's all two-way data bindings. All the way down.) The reason why state management is so valuable is that it dramatically reduces the number of possible paths, and the predictability of where to check first. It categorically shifts the cyclomatic complexity, and efficacy of developer guesswork, down several orders of magnitude.

That's because, instead of passing state through all the little various components and pieces on the page, you keep it all in one big global place, called the *store*. And the store is responsible for passing it down to each individual piece. (You might realize, this is kind of like a giant, global mediator.)

![08 global state](/images/chapters/2/08.png)

It might look messy because I had to draw arrow, but remember that form there in the middle? It means we have a total possible level of cyclomatic complexity of....

One.

And for events?

![global state + events](/images/chapters/2/09.png)

One. Each different little component can only dispatch an event to the store. And what makes the store so special?

It reduces the amount of things a programmer has to think about from potentially everything, to a really simple formula.

```
new state = old state + event
```

The cyclomatic complexity of any given thing on the page is, in most cases, reduced to two. And if there's a dependency chain there, other events you have to understand, there's an extremely formal, clear and explicit pathway to follow about and reason inside. All state can only flow in one possible direction, and this is what's meant by undirectional data flow.

Additionally, this is really, really easy to test. And if you don't have to go manually check everything to see if you broke it every time you make a change, and that saves you *so* much time.

But there's another benefit. If we're able to represent the entire state of a page at a given point in time, and then have an action take place... then it wouldn't be that farfetched to be able to replay what happened.

What if QA people could, upon finding a bug, export that bug and send it over to a developer who could replay it on their computer? **WHAT IF WE COULD EXPORT BUGS!?**

Well, you can. The most popular implementation of this pattern is called Redux, and this site is built with it. Tested, proven tools already exist that work with Redux, and Redux works with *any other framework*.

![redux dev tools](/images/chapters/2/010.png)

Did you notice the import/export buttons? Not only is that not a pipe dream, the ability to export bugs comes *by default.* It's already built. It already works. The only tiny tiny bummer of all of this, is that by adopting Redux + Polymer, you'll probably have way fewer bugs to even do this with. (Like I said... tiny.)

This means, you get all the advantages of the state management provided by web framework, with none of the performance overhead.

### Developer Tools

The other thing that sucks about Polymer/Web Components is that, once you know where your state is, what your scope is, how can you tell what's happening with it?

This is a problem that's also completely solvable, via building a browser plugin. Here's what it would need to do:

* Show me the hierarchy of components (without all the superfluous dom components - we have the regular inspector for that)
* Show me, for a specific component, what data it has.
* Show me, for a specific component, what events it sends out
* Show me, for a specific component, what events it receives.

This is completely 100% possible and viable. I just haven't had time to do it, yet, and decided to type this up first.

## Conclusion

If you want the massive performance, forward compatibility, and complete portability upsides of Polymer with none of the downsides - aka if you want to be able to ship things in Polymer/Web Components that are fast and that people use - this is what needs to happen.

**There must be effective teaching material.** And that's what this Polymer Knowledge Center is - teaching-focused documentation, aimed at taking a developer from zero to their first production bug fix as fast as possible. There must be a known, useful escalation chain so developers don't spend time *sitting at stuck* - even if that just means knowing who to ask and being able to do it.

**Adopt Redux for state management.** Reduce the number of things a programmer has to hold in their head to make a change from (n^3) to (2 + easy). Let your QA people export bugs directly to your developers.

**Build better tooling.** The only reason there isn't a Polymer browser plugin already is because all the Google engineers are great at using the default Chrome inspector. But it would help streamline the development and understanding of Polymer development by just taking what's already there, already accessible, already happening, and just making it more clear and easy to get to.

Polymer/Web components aren't just one among many choices, they are the *only* choice. Because if most of the people who'll be trying to consume online content *can't do it through the browser*, then something else will fill that need. And that means, it doesn't matter if you know React. It doesn't matter if you know Angular. People won't be using a browser anyway.

But more than that, I think Polymer/Web component based development can be an order of magnitude more effective than their javascript-framework based counterparts, and the distance between here and there is only three things.
